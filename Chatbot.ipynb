{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of each section, I will also be providing links to the documentations for the libraries that I think it would be helpful for. It is always helpful to use the documentation! With libraries like this, you have to get used to them before you understand their capabilities. You won't initially have a good idea of what they can and can't do so searching things up is going to be the default way to learn anything specific to your needs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dependency called pyaudio is troublesome to download. \n",
    "# You may have to use pip install pipwin followed by pipwin install pyaudio in adminstrator mode. \n",
    "# Read more about pipwin before using it, to understand why it exists and what the risks are with \n",
    "# using it's unoffical release downloads.\n",
    "\n",
    "# Speech Recognition\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Text to Speech\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Straightforward Chatbot\n",
    "from transformers import pipeline, Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speech_recognition documentation: https://pypi.org/project/SpeechRecognition/1.2.3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "text = \"\"\n",
    "\n",
    "with sr.Microphone(device_index=0) as mic:\n",
    "    print(\"Listening...\")\n",
    "    audio = recognizer.listen(mic)\n",
    "    recognizer.adjust_for_ambient_noise(mic)\n",
    "    \n",
    "    try: \n",
    "        text = recognizer.recognize_google(audio)\n",
    "    except sr.UnknownValueError: \n",
    "        text = \"Speech not understood\"\n",
    "        \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gTTS and pydub documentation: https://gtts.readthedocs.io/en/latest/, https://github.com/jiaaro/pydub\n",
    "\n",
    "Here we save the audio to a file and replay the file. After importing os, you can use os.remove([filepath]) if you don't want to save the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_object = gTTS(text=\"Hello, how are you doing today?\", lang=\"en\", slow=False)\n",
    "text_object.save(f\"chatbot_recordings/example.mp3\")\n",
    "\n",
    "audio = AudioSegment.from_mp3(f\"chatbot_recordings/example.mp3\")\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straightforward Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformers documentation: https://huggingface.co/docs/transformers/index\n",
    "\n",
    "source code for below: https://huggingface.co/transformers/v4.11.3/_modules/transformers/pipelines/conversational.html\n",
    "\n",
    "This method will simply import your chosen model from Hugging Face's selection of pretrained models and allow you to use it directly. You can then use this output however you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: fa3dc1ef-0212-4061-a389-6e45ba0dc1f1 \n",
      "user >> Do you like the color yellow? \n",
      "bot >> I do! \n",
      "\n",
      "Conversation id: fa3dc1ef-0212-4061-a389-6e45ba0dc1f1 \n",
      "user >> Do you like the color yellow? \n",
      "bot >> I do! \n",
      "user >> Why do you think so? \n",
      "bot >> I like it because it's a nice color. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversational_pipeline = pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\") \n",
    "\n",
    "conv = Conversation(\"Do you like the color yellow?\")\n",
    "print(conversational_pipeline([conv], pad_token_id=50256))\n",
    "\n",
    "conv.add_user_input(\"Why do you think so?\")\n",
    "print(conversational_pipeline([conv], pad_token_id=50256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation id: fa3dc1ef-0212-4061-a389-6e45ba0dc1f1 \n",
      "user >> Do you like the color yellow? \n",
      "bot >> I do! \n",
      "user >> Why do you think so? \n",
      "bot >> I like it because it's a nice color. \n",
      "user >> Do you have another favorite color? \n",
      "bot >> I have a few. \n",
      ", Conversation id: 6d8d6986-c522-4a70-a57f-8e0ecf667817 \n",
      "user >> What do you think about the weather? \n",
      "bot >> It's nice. \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "conv2 = Conversation(\"What do you think about the weather?\")\n",
    "conv.add_user_input(\"Do you have another favorite color?\")\n",
    "print(conversational_pipeline([conv, conv2], pad_token_id=50256))\n",
    "\n",
    "conv2.add_user_input(\"Should I play outside then?\")\n",
    "unprocessed = str(conversational_pipeline([conv2], pad_token_id=50256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation id: 6d8d6986-c522-4a70-a57f-8e0ecf667817 ', 'user >> What do you think about the weather? ', \"bot >> It's nice. \", 'user >> Should I play outside then? ', \"bot >> I'm not sure. \"]\n"
     ]
    }
   ],
   "source": [
    "responses = [resp for resp in unprocessed.split(\"\\n\") if resp != \"\"]\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure. \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[-1].split(\" >> \")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def listen(): \n",
    "    with sr.Microphone() as mic: \n",
    "        print(\"Listening...\")\n",
    "        \n",
    "        audio = recognizer.listen(mic)\n",
    "        recognizer.adjust_for_ambient_noise(mic)\n",
    "\n",
    "        try: \n",
    "            text = recognizer.recognize_google(audio)\n",
    "        except sr.UnknownValueError: \n",
    "            text = \"[BAD]\"\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def speak(text):\n",
    "    \n",
    "    global count\n",
    "    \n",
    "    text_object = gTTS(text=text, lang=\"en\", slow=False)\n",
    "    text_object.save(f\"chatbot_recordings/reply_{count}.mp3\")\n",
    "\n",
    "    audio = AudioSegment.from_mp3(f\"chatbot_recordings/reply_{count}.mp3\")\n",
    "    play(audio)\n",
    "    \n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(history): \n",
    "    responses = [resp for resp in history.split(\"\\n\") if resp != \"\"]\n",
    "    return responses[-1].split(\" >> \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Starting up Chatbot-----\n",
      "Listening...\n",
      "Listening...\n",
      "user >> hey how are you feeling today\n",
      "bot >> I'm feeling pretty good, thanks for asking. \n",
      "Listening...\n",
      "user >> let's talk about something else\n",
      "bot >> I'm not sure what you're talking about. \n",
      "Listening...\n",
      "user >> I just got ice cream today\n",
      "bot >> I'm not sure what you're talking about. \n",
      "Listening...\n",
      "user >> you like ice cream\n",
      "bot >> I like ice cream \n",
      "Listening...\n",
      "user >> it's creep okay bye\n",
      "bot >> I'm not going anywhere. \n",
      "-----Shutting down Chatbot-----\n",
      "[Conversation id: 7f67e602-ff40-4e52-8a9f-8ce278f9504d \n",
      "user >> hey how are you feeling today \n",
      "bot >> I'm feeling pretty good, thanks for asking. \n",
      ", Conversation id: 689ecf46-ca18-4e58-ab20-ba6fe8daa710 \n",
      "user >> let's talk about something else \n",
      "bot >> I'm not sure what you're talking about. \n",
      "user >> I just got ice cream today \n",
      "bot >> I'm not sure what you're talking about. \n",
      "user >> you like ice cream \n",
      "bot >> I like ice cream \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "conversational_pipeline = pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\") \n",
    "conversation = Conversation()\n",
    "history = []\n",
    "\n",
    "print(f\"-----Starting up Chatbot-----\")\n",
    "\n",
    "run = True\n",
    "while run: \n",
    "    \n",
    "    text = listen()\n",
    "    \n",
    "    if text == \"[BAD]\": \n",
    "        speak(\"Sorry, could you repeat that?\")\n",
    "        continue\n",
    "        \n",
    "    elif \"talk about something else\" in text: \n",
    "        history.append(conversation)\n",
    "        conversation = Conversation()\n",
    "        \n",
    "    elif any([stop in text for stop in [\"bye\", \"exit\", \"close\"]]): \n",
    "        history.append(conversation)\n",
    "        conversation = Conversation()\n",
    "        run = False\n",
    "        \n",
    "    print(f\"user >> {text}\")\n",
    "    conversation.add_user_input(text)   \n",
    "    \n",
    "    resp = get_response(str(conversational_pipeline([conversation], pad_token_id=50256)))\n",
    "    speak(resp)\n",
    "    print(f\"bot >> {resp}\")\n",
    "        \n",
    "        \n",
    "print(f\"-----Shutting down Chatbot-----\")\n",
    "print(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
